{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2: Polynomial interpolation in 1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Material for this worksheet can be found in the AE2220-I lecture notes Chapter 3.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of constructing an approximating function which passes <i>exactly</i> though specified data points is called <i>interpolation</i>.  We concern ourselves with approximating the real function of one variable $f:\\mathbb{R}\\rightarrow\\mathbb{R}$, on the interval $[a,b]$.  We assume knowledge of $n+1$ samples of $f(x)$ at <i>grid</i> locations $(x_0,\\dots,x_n)$, with which to build the approximating function $\\phi(x)$.  The requirement that $f$ passes through the data-points can be formulated as:\n",
    "$$\n",
    "f(x_i) = \\phi(x_i) \\quad\\mbox{ for }\\quad i = 0,\\dots,n,\n",
    "$$\n",
    "known as the <i>interpolation conditions</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'axes.labelsize': 18})\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test the method, we choose a (known) analytic function, and sample it at the grid points.  Normal the exact function $f$ will be unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = 0., 5.\n",
    "n = 6\n",
    "\n",
    "def f(x): \n",
    "    return np.sin(np.pi*x/2.)\n",
    "\n",
    "xx = np.linspace(a,b,101)\n",
    "plt.plot(xx, f(xx))\n",
    "plt.xlabel(r'$x$'); plt.ylabel(r'$f$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of the grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume that we are free to choose the grid nodes $(x_0,\\dots,x_n)$ - we may even choose them outside the interval $[a,b]$.  An apparently logical choice is uniformly spaced nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_uniform(n): return np.linspace(a, b, n+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, as we will see, uniform spacing performs badly in some situations.  In fact the interpolation error is minimized using Chebychev nodes, which on the interval $[-1,1]$ are:\n",
    "$$\n",
    "\\xi_i = \\cos\\left( \\frac{2i+1}{2(n+1)}\\,\\pi\\right),\\quad i=0,\\ldots,n.\n",
    "$$\n",
    "These can be easily scaled to the interval $[a,b]$ with the linear map:\n",
    "$$\n",
    "x_i = (b-a) \\frac{-\\xi_i+1}{2} + a, \\quad\\mbox{for } i=0,\\dots,n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_chebychev(n):\n",
    "    xi = np.cos( np.pi/(2*(n+1)) * (2*np.linspace(1, n+1, n+1) - 1) )\n",
    "    return ((-xi + 1)/2) * (b-a) + a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, just to see how bad things can get with a poor choice, we consider randomly chosen nodes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grid_random(n): return np.random.rand(n+1) * (b-a) + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(grid_uniform(n),   np.ones(n+1)*2, 'ok', label='uniform')\n",
    "plt.plot(grid_chebychev(n), np.ones(n+1)*1, 'or', label='chebychev')\n",
    "plt.plot(grid_random(n),    np.ones(n+1)*0, 'ob', label='random')\n",
    "plt.legend()\n",
    "plt.ylim(-1,4)\n",
    "plt.xlabel(r'$x$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between uniform and Chebychev becomes more noticable for larger $n$. The grid used in the following calculations is selected here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid = grid_uniform(n)  # Choose the grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selection of basis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of the basis is to provide a set of functions, which when added together with correct weights, will compose $\\phi(x)$, which in turn approximates the function $f(x)$:\n",
    "$$\n",
    "\\phi(x) := \\sum_{i=0}^n a_i \\varphi_i(x),\n",
    "$$\n",
    "where $a_i$ are weights to be found, and $\\varphi_i(x)$ are $n+1$ basis functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are concerned with polynomial approximants (because of Weierstrass, Theorem 3.4, and Uniqueness of Polynomial Interpolation, Theorem 3.5) our basis should be polynomial too.  However there are several choices.\n",
    "\n",
    "One natural basis for polynomials are the <b>monomials</b>:\n",
    "$$\n",
    "\\begin{align*}\n",
    "m_0(x) &= 1 \\\\\n",
    "m_1(x) &= x \\\\\n",
    "m_2(x) &= x^2 \\\\\n",
    "\\vdots \\quad & \\quad\\vdots \\\\\n",
    "m_n(x) &= x^n,\n",
    "\\end{align*}\n",
    "$$\n",
    "It is self-evident that a sum of these basis functions can produce any polynomial of degree $n$.  Notice that this basis is independent of the grid points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def basis_monomial(x, grid):\n",
    "    phi = np.zeros(len(grid))\n",
    "    for i in range(len(grid)): phi[i] = x**i\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>Newton basis</b> is a third choice that results in a lower-triangular interpolation matrix $A$:\n",
    "$$ \n",
    "\\pi_0(x) = 1,\\quad \\pi_k(x) = \\prod_{j=0}^{k-1} (x-x_j),\\quad k=1,2,\\ldots,n.\n",
    "\\label{newtonbasis}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def basis_newton(x, grid):\n",
    "    phi = np.ones(len(grid))\n",
    "    for i, xi in enumerate(grid):\n",
    "        for j in range(i):\n",
    "            phi[i] *= (x - grid[j])\n",
    "    return phi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <b>Lagrange basis</b> function $l_i(x)$ takes the value $1$ at grid point $x_i$, and $0$ at all other grid points (we will check this in the next section), and has the form:\n",
    "$$\n",
    "l_i(x) = \\prod_{j=0, j \\neq i}^{n} \\frac{x-x_j}{x_i-x_j},\\quad i=0,\\ldots,n.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "**(a) Implement a Lagrange basis in the function *basis_lagrange()* which takes the scalar $x \\in \\mathbb{R}$, the grid locations $(x_0,\\dots,x_n)$ in *grid*.  It should return all $n+1$ Lagrange basis functions, evaluated at $x$.**\n",
    "\n",
    "**(b) Use plot_basis to plot the basis functions $l_0(x),\\dots,l_n(x)$ on the interval $[a,b]$.  Verify from your plot that your basis-functions satisfy the condition:\n",
    "$$\n",
    "l_i(x_j) = \\delta_{ij} := \\begin{cases} 1 & i = j \\\\ 0 & i \\neq j \\end{cases}.\n",
    "$$**\n",
    "\n",
    "**(c) It is easy to see that we can produce all polynomials of degree $n$ from a sum of monomials $m_i(x)$.  But can we produce all polynomials of degree $n$ as a sum of $l_i(x)$?  Hint:**\n",
    "\n",
    "  0. **What degree are $l_i$?**\n",
    "  0. **What do we know about a polynomial that passes through $n+1$ points?**  \n",
    "  0. **Can we construct a sum of $l_i(x)$ that pass through any $n+1$ points?**\n",
    "  \n",
    "**(d) Finally: There is a strong connection to linear algebra.  The equivalent question there is: Does a particular set of vectors $\\mathbf{l_i}$ span the linear vector-space of dimension $n+1$?  If it does then $\\mathbf{l_i}$ is called a *basis*.  Can you make this connection more precise?  In particular what vector $\\mathbf{l_i}$ corresponds to the function $l_i$?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def basis_lagrange(x, grid):\n",
    "    pass ### TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_basis(basisfn):\n",
    "    xx = np.linspace(a, b, 101)\n",
    "    phi = np.zeros((101, n+1))\n",
    "    for i,x in enumerate(xx): \n",
    "        phi[i] = basisfn(x,grid)\n",
    "    for j in range(n+1):\n",
    "        plt.plot(xx, phi[:,j])\n",
    "    plt.plot(grid, np.zeros(grid.shape), 'ok', label='samples')\n",
    "    plt.xlabel(r'$x$'); plt.ylabel(r'$l_i$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_basis(basis_lagrange)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the interpolation conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interpolation conditions state that $\\phi(x_j) = f(x_j)$ at all mesh points $x_j$.  Substituting the definition of $\\phi(x)$, this condition becomes:\n",
    "$$\n",
    "\\sum_{i=1}^n a_i \\varphi_i(x_j) = f(x_j) \\quad\\mbox{for all}\\quad j\\in\\{0,\\dots,n\\}\n",
    "$$\n",
    "which can be rewritten in matrix form:\n",
    "$$\n",
    "A \\mathbf{a} = \\mathbf{f}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "\\begin{align}\n",
    "   \\mathbf{a} &=& (a_0,\\dots, a_n) \\\\\n",
    "   \\mathbf{f} &=& (f(x_0), \\dots, f(x_n)) \\\\\n",
    "   A_{ij} &=& \\varphi_i(x_j)\n",
    "\\end{align}\n",
    "$$\n",
    "The right-hand side (RHS) $\\mathbf{f}$ can be evaluated as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def interpolation_rhs(grid):\n",
    "    rhs = np.zeros(n+1)\n",
    "    for i,x in enumerate(grid):\n",
    "        rhs[i] = f(x)\n",
    "    return rhs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rhs = interpolation_rhs(grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "\n",
    "**(a) Implement a function *interpolation_matrix()* which takes two arguments, a list of the grid nodes, and a function which describes the basis.  It should then return the interpolation matrix $A$.** \n",
    "\n",
    "**(b) Print the matrix using *print(A)*, and plot it, using *plt.imshow(A, interpolation='none')*.** \n",
    "\n",
    "**(c) How does the form of the matrix differ for monomial, Newton and Lagrange bases?  Why do the matrices have this structure?  The next step involves solving for the coefficients $\\mathbf{a}$ - which matrix is easiest to invert?  Which is most difficult?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def interpolation_matrix(grid, basisfn):\n",
    "    n = len(grid)-1\n",
    "    A = np.zeros((n+1,n+1))\n",
    "    pass ### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The potentially expensive step (computationally speaking) is solving for the coefficients $\\mathbf{a}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "aa = np.linalg.solve(A, rhs)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reconstructing the function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ultimately the purpose is to reconstruct the function - here we just evaluate $\\phi(x)$ using the basis functions and coefficients $\\mathbf{a}$ found above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reconstruct(x, grid):\n",
    "    return np.sum(aa * basis_lagrange(x, grid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xx2 = np.linspace(0,1,101)\n",
    "reconstruction = np.zeros(len(xx2))\n",
    "for i,x in enumerate(xx): \n",
    "    reconstruction[i] = reconstruct(x, grid)\n",
    "plt.plot(xx, f(xx), label='original')\n",
    "plt.plot(grid, f(grid), 'ok', label='samples')\n",
    "plt.plot(xx, reconstruction, label='interpolation')\n",
    "plt.xlabel(r'$x$')\n",
    "plt.legend(loc='lower right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we get a numerical result like this, we should check to see if it meets our expectations.  Our basic expectations are:\n",
    "\n",
    "* The interpolant is smooth;\n",
    "* That it's a degree $n$ polynomial (check the number of extrema);\n",
    "* Which passes through the sample points (easy to check).\n",
    "\n",
    "If these are not true, something is seriously wrong.   On a higher level we have expectations related to **consistency**, **convergence** and **stability**:\n",
    "\n",
    "* The interpolant approximates $f(x)$ increasingly accurately as $n$ is increased.\n",
    "\n",
    "I.e. that the error diminishes as $n\\rightarrow\\infty$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also ask: What expectations do we have regarding the influence of the choice of basis on the interpolant $\\phi(x)$?  What about the choice of grid?  Do these inflence the numerical result or not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error behaviour"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One reasonable definition of error is:\n",
    "$$\n",
    "e_n(x) := f(x) - \\phi(x)\n",
    "$$\n",
    "And from the notes we have a theorem regarding this error (Cauchy):\n",
    "\n",
    "If $f \\in C^{n+1}([a,b])$, then for any grid $X$ of $n+1$ nodes and for any $x \\in [a,b]$, the interpolation error at $x$ is\n",
    "$$\n",
    "  e_n(f;x) := f(x) - \\phi(x) = \\frac{f^{(n+1)}(\\xi)}{(n+1)!}\\,\\omega_{n+1}(x),\n",
    "$$\n",
    "where $\\xi = \\xi(x) \\in (\\min_k(x_k,x), \\max_k(x_k,x)) \\subset [a,b]$ and $\\omega_{n+1}(x)$ is the <i>nodal polynomial</i> associated with the grid $\\mathbf{x}$, defined as,\n",
    "$$\n",
    "\\omega_{n+1}(x) := \\prod_{i=0}^n (x-x_i).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with this error estimate is that it's not readily <i>computable</i>, as computing $\\xi$ and then $f^{(n+1)}(\\xi)$ is not easy.  As a compromise we can assume that \n",
    "$$\n",
    "f^{(n+1)}(\\xi) = \\mathcal{O}(1)\n",
    "$$\n",
    "i.e. that the left-hand side doesn't depend on $n$.  This allows us to use the error estimate:\n",
    "$$\n",
    "\\hat e_n(x) := \\frac{1}{(n+1)!}\\prod_{i=0}^n (x-x_i).\n",
    "$$\n",
    "Let's compare theory with practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from math import factorial\n",
    "def error_estimate(x):\n",
    "    return np.abs(np.prod(x - grid) / factorial(len(grid)))\n",
    "\n",
    "### Compute estimate at each plotting point\n",
    "errorest = np.zeros(len(xx))\n",
    "for i,x in enumerate(xx): \n",
    "    errorest[i] = error_estimate(x)\n",
    "\n",
    "### Do the plotting\n",
    "plt.plot(xx, np.abs(f(xx) - reconstruction), label='Error exact')\n",
    "plt.plot(grid, 0*grid, 'ok', label='samples')\n",
    "plt.plot(xx, errorest, label='Error estimate')\n",
    "plt.xlabel(r'$x$'); plt.ylabel(r'Error')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The form of the error is correct, but the scale is wrong - because we don't know $f^{(n+1)}(\\xi)$.  On the other hand, as we increase the number of points $f^{(n+1)}(\\xi)$ will stay approximately constant, so the error estimate will describe well the *rate* of reduction of the error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3: A key message of this study is that convergence of polynomial interpolation depends strongly on the choice of grid and the underlying function $f(x)$.  We want to verify these statements - we look at convergence plots.**\n",
    "\n",
    "**Start with the function below *poly_interp()*,  which does one-shot interpolation of $f$ given a *grid*, a *basis* (e.g. the function basis_lagrange), and an array of points *xx* at which to evaluate the reconstruction:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def poly_interp(xx, f, grid, basis):\n",
    "    A = interpolation_matrix(grid, basis)   ### Interpolation conditions\n",
    "    ff = np.array([f(xi) for xi in grid])\n",
    "    aa = np.linalg.solve(A,ff)\n",
    "    basisxx = np.zeros((len(xx),len(grid))) ### Basis functions at all x values in xx\n",
    "    for i,x in enumerate(xx):\n",
    "        basisxx[i,:] = basis(x,grid)\n",
    "    return np.dot(basisxx, aa)              ### Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Usage is, for example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_grid = grid_chebychev(10)\n",
    "f_prediction = poly_interp(xx, f, my_grid, basis_monomial)\n",
    "plt.plot(xx, f_prediction)\n",
    "plt.plot(xx, f(xx))\n",
    "plt.plot(my_grid, f(my_grid), 'ok')\n",
    "plt.xlabel(r'$x$'); plt.ylabel(r'$f$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a) Implement a function to approximately compute the (scalar) error:\n",
    "$$\n",
    "\\epsilon_n := \\mathrm{max}_{x\\in[a,b]} | e_n(x) |\n",
    "$$\n",
    "for a given $f$, grid and basis.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def error_max(xx, f, grid, basis):\n",
    "    pass ### TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Make a plot of the above error $\\epsilon_n$ against the number of nodes.  Use a uniform grid an $n \\in \\{2,\\dots,20 \\}$.  Use a log-scale for the error.  You should see a line with error decreasing towards zero.**\n",
    "\n",
    "**(c) Investigate the behaviour of the interpolation error.  Does the basis-choice have an effect on the error?  Does the grid?  What is the best choice of basis/grid, in terms of minimizing the error for a given number of nodes?  [Note: Use the function below, that produces a convergence plot for a given function *f_fn*, *grid_fn* (i.e. grid_uniform, grid_random, or grid_chebychev), and a given *basis_fn*.  By calling it multiple times, several convegence plots can be compared on a single axis.]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_convergence(f_fn, grid_fn, basis_fn):\n",
    "    nn, linfty = range(2, 20), []\n",
    "    xx = np.linspace(a, b, 1001)\n",
    "    for n in nn:\n",
    "        linfty.append(error_max(xx, f_fn, grid_fn(n), basis_fn))\n",
    "    plt.plot(nn, np.log10(np.array(linfty)), '-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_convergence(f, grid_uniform, basis_lagrange)\n",
    "plot_convergence(f, grid_chebychev, basis_lagrange)\n",
    "plot_convergence(f, grid_random, basis_lagrange)\n",
    "plt.xlabel(r'$N$'); plt.ylabel(r'$\\log_{10}(\\epsilon)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d) Our interpolant should be accurate for a range of functions.  Examine the interpolants and the convergence for the following functions.  What aspects of the theory can you see reproduced in the results?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def f_poly5(x): return 0.001*x**5 + 0.02*x**3 - x  # Polynomial\n",
    "def f_step(x): return np.sign(x-2)                 # Discontinuous at x=2\n",
    "def f_abs(x): return np.abs(x-2)                   # Discontinuous derivative at x=2\n",
    "def f_abs3(x): return np.abs((x-2)**3)             # Discontinuous 3rd derivative at x=2\n",
    "def f_runge(x): return 1./(1+(x-2)**2)             # Infinitely differentiable (everywhere)\n",
    "def f_gauss(x): return np.exp(-(x-2)**2/2.)        # Very similar curve to above\n",
    "def f_custom(x): pass                              # Your own function  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
