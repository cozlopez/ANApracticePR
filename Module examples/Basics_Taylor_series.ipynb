{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating functions with Taylor series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand and analyse numerical approximations, we need a mathematical toolbox.  Our number one tool is Taylor's expansion.  With this we can take an arbetrary (N+1)-times continuously differentiable function $f(x) \\in C^{N+1}([a,b])$, and approximate it at any point $x_0 \\in (a,b)$ as a <b>polynomial</b> of degree up to $N$.  Since we can \"work\" with polynomials easily (we can differentiate them, integrate them, etc.) this simplifies dramatically.  The tool is as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taylor's theorem "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let $f(x)$ be a $f: \\mathbb{R}\\rightarrow\\mathbb{R}$ which is $N+1$-times continuously differentiable on the interval $[x_0, x]$ (the first $N+1$ derivatives exist and are continuous).  Then the Taylor expansion of $f(x)$ about $x_0$ is\n",
    "$$\n",
    "f(x) = \\sum_{n=0}^N \\frac{f^{(n)}(x_0)}{n!} (x-x_0)^n + \\mathcal{O}(x-x_0)^{N+1}.\n",
    "$$\n",
    "For small $(x-x_0)$ we expect the last term, the <i>truncation error</i> to be small, and therefore the sum to be a good approximation to $f(x)$.  Note that the sum contains only powers of $x$ - it is therefore a <b>polynomial</b> in $x$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The simplest case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try using this, in the reduced form\n",
    "$$\n",
    "f(x) \\approx p_1(x) := f(x_0) + \\left.\\frac{df}{dx}\\right|_{x_0}(x-x_0)\n",
    "$$\n",
    "where we only look at the initial two terms, and ignore the remainder (we use the less-precise \"approximate equality\" $\\approx$).  To define $p_2(x)$ we use the \"definition\" operator $:=$.  The subscript \"$1$\" indicates that the polynomial approximation is of degree 1 (i.e. $x^1$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "\n",
    "**(a) What is the minimum number of times $f(x)$ must be differentiable to use this form?**\n",
    "\n",
    "**(b) How should $x$ and $x_0$ be related to make the approximation good?**\n",
    "\n",
    "**(c) Give an example of a function $f(x)$ on the interval $x\\in[-1,1]$ that is (i) not differentiable, (ii) exacly one-time differentiable, (iii) exactly two-times differentiable.  (Hint for (iii): consider that differentiation is the inverse operation of differentiation.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see how good the approximation is in practice:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def f(x): return np.exp(0.5*x)\n",
    "x0 = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need the derivatives (complete these yourself):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dfdx(x):   return 0.5*np.exp(0.5*x)\n",
    "def d2fdx2(x): return 0.5**2*np.exp(0.5*x)\n",
    "def d3fdx3(x): return 0.5**3*np.exp(0.5*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which allows us to construct $p_1(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p1(x): return f(x0) + dfdx(x0)*(x-x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "xx = np.linspace(-3,3,101)\n",
    "plt.plot(x0,f(x0),'ok')\n",
    "plt.plot(xx, f(xx), label=r'$f(x)$')\n",
    "plt.plot(xx, p1(xx), label=r'$p_1(x)$')\n",
    "#plt.plot(xx, p2(xx), label=r'$p_2(x)$')\n",
    "plt.legend(loc='upper left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a straight line, passing through $(x_0,f(x_0))$, tangent to $f(x)$ at that point.  This line is a <i>linear approximation</i> of $f(x)$ at $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher-order approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the general formula for Taylor's theorem, we can write down the quadratic approximant to $f(x)$ at $x_0$:\n",
    "$$\n",
    "f(x) \\approx p_2(x) := f(x_0) + \\left.\\frac{df}{dx}\\right|_{x_0}(x-x_0)+ \\frac{1}{2!}\\left.\\frac{d^2f}{dx^2}\\right|_{x_0}(x-x_0)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting from the code for $p_1(x)$ write down the code for $p_2(x)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def p2(x): return f(x0) + dfdx(x0)*(x-x0) + .5 * d2fdx2(x0)*(x-x0)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add it to the plot above (by uncommenting the commented line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** \n",
    "\n",
    "**(a) What can you say about the accuracy of the quadratic approximation $p_2$, compared to the linear approximation $p_1$?  Will the accuracy of $p_2$ be better everywhere?**\n",
    "\n",
    "**(b) Modify the definition of $f(x)$ above (and remember to modify its derivatives!).  Choose also an approprate $x_0$.  How does Taylor's approximation perform with various functions?  Some suggestions $f(x) = \\sin(x)$, $f(x) = |x|$, $f(x) = x^2$.  Explain your observations in terms of your knowledge of the form of the truncation error.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the approximation error as:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$e_i(x) := f(x) - p_i(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to compare this to the (theoretical) truncation error given by Taylor's expansion.  The Lagrange form of the truncation error (see Notes Theorem 1.1) is not usually computable due to the unknown $\\xi$.  But we can approximate it by computing instead the next term in the series:\n",
    "\n",
    "$$\n",
    "f(x) = p_1(x) + e_1(x) = f(x_0) + \\left.\\frac{df}{dx}\\right|_{x_0}(x-x_0) + e_1(x)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So that it's reasonable to guess:\n",
    "$$\n",
    "e_1(x) \\approx \\frac{1}{2!}\\left.\\frac{d^2f}{dx^2}\\right|_{x_0} (x-x_0)^2\n",
    "$$\n",
    "With error proportional to $(x-x_0)^3$.  Let's compare this error to the actual error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def e1_exact(x): return f(x)-p1(x)\n",
    "def e1_approx(x): return .5*d2fdx2(x0)*(x-x0)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(x0,0,'ok')\n",
    "plt.plot(xx, e1_exact(xx),label=r'$e_1$-Exact')\n",
    "plt.plot(xx, e1_approx(xx),label=r'$e_1$-Approx')\n",
    "plt.xlabel(r'$x$')\n",
    "plt.ylabel(r'$e$')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should see a rough match between the approximate error and the prediction.  Notice that the form of the error (near $x_0$) is the same (quadratic), and that the agreement is also best near $x_0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:**\n",
    "\n",
    "**(a) Perform the same comparison of exact and approximate error for $p_2(x)$.  Note that the approximate error will be cubic in $x$ in this case.**\n",
    "\n",
    "**(b) Perform the same comparison for other functions.  Under what conditions is the approximate error good and bad?**\n",
    "\n",
    "**(c) What are the benefits of theoretical analysis of the error (Lagrange reminder, etc.), if we can just compute the error numerically, as we have done above?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please <b>memorize</b> the following two (equivalent) forms of Taylor's expansion - they will be used throughout the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x) = f(x_0) + \\left.\\frac{df}{dx}\\right|_{x_0} (x-x_0) + \\frac{1}{2!}\\left.\\frac{d^2f}{dx^2}\\right|_{x_0} (x-x_0)^2 + \\mathcal{O}(x-x_0)^3\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, with $h := x-x_0$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x_0+h) = f(x_0) + \\left.\\frac{df}{dx}\\right|_{x_0} h + \\frac{1}{2!}\\left.\\frac{d^2f}{dx^2}\\right|_{x_0} h^2 + \\mathcal{O}(h^3)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this second form for the approximation to be accurate we must have $h << 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multidimensional Taylor expansion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taylor's expansion generalizes to functions of $2$ inputs:\n",
    "$$\n",
    "\\begin{align}\n",
    "f(x_0 + h_x,y_0 + h_y) &=& f(x_0,y_0) \\\\\n",
    " &+& \\left.\\frac{df}{dx}\\right|_{x_0,y_0} h_x + \\left.\\frac{df}{dy}\\right|_{x_0,y_0} h_y \\\\\n",
    " &+& \\frac{1}{2!}\\left[\\left.\\frac{d^2f}{dx^2}\\right|_{x_0,y_0} h_x^2 + \n",
    "                       2 \\left.\\frac{d^2f}{dx\\,dy}\\right|_{x_0,y_0} h_x h_y + \n",
    "                       \\left.\\frac{d^2f}{dy^2}\\right|_{x_0,y_0} h_y^2\\right] \\\\\n",
    " &+& \\mathcal{O}(h_x^3, h_x^2 h_y, h_x h_y^2, h_y^3),\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and to functions of $m$ inputs:\n",
    "$$\n",
    "\\begin{align}\n",
    "f(\\mathbf{x}_0 + \\mathbf{h}) &=& f(\\mathbf{x}_0) \\\\\n",
    "   &+& \\sum_{i=1}^m \\left.\\frac{df}{dx_i}\\right|_{\\mathbf{x}_0} h_i \\\\\n",
    "   &+& \\frac{1}{2!}\\sum_{i=1}^m \\sum_{j=1}^m \\left.\\frac{d^2f}{dx_i\\,dx_j}\\right|_{\\mathbf{x}_0} h_i h_j \\\\\n",
    "   &+& \\frac{1}{3!} \\sum_{i=1}^m \\sum_{j=1}^m \\sum_{k=1}^m \\left.\\frac{d^3f}{dx_i\\,dx_j\\,dx_k}\\right|_{\\mathbf{x}_0} h_i h_j h_k \\\\\n",
    "   &+& \\mathcal{O}(\\mathbf{h}^4)\n",
    "   \\end{align}\n",
    "$$\n",
    "where $\\mathbf{x}_0 = (x_1,\\dots,x_m)$ and $\\mathbf{h} = (h_1,\\dots,h_m)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In $m$-dimensions Taylor's expansion also correponds to a <b>local approximation of the function $f(\\mathbf{x})$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise X (Advanced): Verify numerically that Taylor's expansion approximates $f(x)$ in a 2-variable case.  Use the \"plt.contour()\" to plot surfaces.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
