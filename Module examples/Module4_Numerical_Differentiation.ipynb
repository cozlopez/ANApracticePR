{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 4: Numerical Differentiation #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Material for this worksheet can be found in the AE2220-I lecture notes Chapter 6.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taylor-series construction of difference formulae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One very useful application of the Taylor Series is to approximate derivatives.  Once we can approximate derivatives we can start thinking about approximating Ordinary/Partial Differential Equations (ODEs/PDEs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the *Taylor series* expression:\n",
    "$$\n",
    "f(x + h) = f(x) + f'(x)h + \\frac{f''(x)}{2}h^2 + ... + \\frac{f^{k-1}(x)}{(k-1)!}h^{k-1} + R_k(\\xi)\n",
    "$$\n",
    "where\n",
    "$$\n",
    "R_k(\\xi) = \\frac{f^k(\\xi)}{k!}h^k, \\hspace{1cm}  x < \\xi < x+h\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearranging so that $f'$ is on the left, and everything else is on the right, we obtain:\n",
    "\n",
    "$$\n",
    "f'(x) = \\frac{f(x+h)-f(x)}{h} + \\frac{f''(x)}{2}h + ... +\\frac{f^{k-1}(x)}{(k-1)!}h^{k-2} + O(h^{k-1})= \\frac{f(x+h)-f(x)}{h} + O(h) \n",
    "$$\n",
    "\n",
    "Once more the error is in terms of $h$, so by choosing $h$ small enough, the error can become as small as we like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assume $f$ is sampled uniformly at points $x_i$ a distance $h = x_{i+1}-x_i$ apart.  Let $f_i := f(x_i)$, then the above becomes the *forward difference formula* (FDF):\n",
    "\n",
    "$$\n",
    "f'(x_i) =  \\frac{f_{i+1}-f_i}{h} + O(h) \n",
    "$$\n",
    "\n",
    "This is the simplest expression for the first derivative.  A different expression is obtained by using $x_{i-1}$; the *backward difference formula* (BDF): \n",
    "\n",
    "$$\n",
    "f'(x_i) =  \\frac{f(x)-f(x-h)}{h} + O(h) =\\frac{f_i-f_{i-1}}{h} + O(h) \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We introduce the *discrete derivative operator* $D_h$ - the numerical equivalent of $d/dx$:\n",
    "$$\n",
    "D_h\\; f(x) := \\frac{f(x+h) - f(x)}{h} \\simeq \\frac{d}{dx} f(x),\n",
    "$$\n",
    "where we used FDF to define $D_h$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams.update({'axes.labelsize': 18})\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume we have the function $f(x)=\\sin(x^2)$ in an interval [0,5]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a, b = 0., 5.\n",
    "h = 0.1         # spacing between consecutive points\n",
    "n = (b-a)/h     # number of points n+1\n",
    "\n",
    "def f(x): return np.sin(x**2)\n",
    "def f_prime(x): return np.cos(x**2)*2*x\n",
    "\n",
    "xi = np.linspace(a,b,n)          # Samples \n",
    "fi = f(xi)                       # Data \n",
    "xx = np.linspace(a,b,1001)       # Points for plotting\n",
    "\n",
    "plt.figure(figsize=(12,4))\n",
    "plt.subplot(121)\n",
    "plt.plot(xx, f(xx))              # Plot fn\n",
    "plt.plot(xi, fi, 'ok')\n",
    "plt.xlabel(r'$x$'); plt.ylabel(r'$f$')\n",
    "plt.subplot(122)             \n",
    "plt.plot(xx, f_prime(xx))        # Plot derivative\n",
    "plt.xlabel(r'$x$'); plt.ylabel(r\"$f'$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation of the forward difference is as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Df_fdf = (fi[1:] - fi[:-1]) / h   # Numerical derivatives\n",
    "xi_fdf = xi[:-1]                  # Locations of derivatives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the derivative at point $x_n$ is not computed, as the data $x_{n+1}$ needed by the FDF is not available - hence `xi_fdf` describes only the first $n$ samples.  Let's examine the performance of the FDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_derivatives(xi, Df):\n",
    "    plt.figure(figsize=(12,4))\n",
    "    plt.subplot(121)\n",
    "    plt.plot(xx, f_prime(xx), label='Exact')\n",
    "    plt.plot(xi, Df, 'ok', label=r'$D_h f$')\n",
    "    plt.xlabel(r'$x$'); plt.ylabel(r\"$f'$\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.subplot(122)\n",
    "    plt.plot(xi, Df - f_prime(xi), 'r', label=r'$D_h f$')\n",
    "    plt.xlabel(r'$x$'); plt.ylabel(r\"$\\epsilon$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    " plot_derivatives(xi_fdf, Df_fdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 1:**\n",
    "**(a) Modify the above code for FDF to get BDF (backward differences).  Be careful at boundaries - now there will be no derivative computed at sample $x_0$.  What do you notice about the expression for `Df_bdf` compared to `Df_fdf`? What do you notice about the error-plots compared to FDF?  What do you notive about the *sign* of the error?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TODO\n",
    "Df_bdf =                         # Numerical derivatives\n",
    "xi_bdf =                         # Locations of derivatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_derivatives(xi_bdf, Df_bdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) What happens for changing $h$?  Theory says the error is linear in $h$, is this true? (Divide $h$ by 10, and see if the error reduces by about 10.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Higher-order difference formulae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always in this course, we want to obtain small errors as \"quickly\" as possible - i.e. with the fewest possible samples of $f$.  Specifically we would like $\\epsilon = O(h^p)$ for some positive integer $p$.  The schemes above have $p=1$ - what we call \"low\"-order.  Taylor series so that higher order terms cancel out. For example, if we substract the series for the forward difference and the series for the backward difference: \n",
    "\n",
    "\\begin{align}\n",
    "f(x + h) &= f(x) + f'(x)h + \\frac{f''(x)}{2}h^2 + \\frac{f'''(x)}{3!}h^3 +... + R_k(\\xi_1) \\qquad \\text{Forward}\\\\\n",
    "f(x - h) &= f(x) - f'(x)h + \\frac{f''(x)}{2}h^2 - \\frac{f'''(x)}{3!}h^3 +... + R_k(\\xi_2) \\qquad \\text{Backward}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rearranging:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x + h) - f(x - h) = 2f'(x)h + 2\\frac{f'''(x)}{3!}h^3 + ... \n",
    "\\hspace{0.5cm} \\implies \\hspace{0.5cm}\n",
    "f'(x) = \\frac{f(x + h) - f(x - h)}{2h} + O(h^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For uniformly spaced samples $x_i$, we get the *central difference formula* (CDF): "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f'(x_i) = \\frac{f_{i+1} - f_{i-1}}{2h} + O(h^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:**\n",
    "**(a) Again, modify the code for the forward difference to implement a central difference.  Now, only derivatives from $x_1,\\dots,x_{n-1}$ will be computable.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### TODO\n",
    "Df_cdf =                 # Numerical derivatives\n",
    "xi_cdf =                 # Locations of derivatives "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_derivatives(xi_cdf, Df_cdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b) Is the error lower compared to FDF and BDF?  If $h$ is reduced by a factor of 10, by how much is the error in CDF reduced? (Answer first based on theory, then by numerical experiment.)**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
